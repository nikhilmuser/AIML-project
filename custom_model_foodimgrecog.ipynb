{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikhilmuser/AIML-project/blob/main/custom_model_foodimgrecog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TPNVEg7-YBAd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb3116a9-ebf2-456d-b3f2-469870976fb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install streamlit -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lt2eBNi4gW5I",
        "outputId": "6ec96b80-3bbd-45b9-c744-ade42f89cec0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKJTHQohYQxk",
        "outputId": "8f92d865-489f-435a-9ee9-7d13a388b45c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "34.30.194.89\n"
          ]
        }
      ],
      "source": [
        "!curl -s ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vii12cToYeLm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import streamlit as st\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpKZI0FUY-1o"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import random\n",
        "import collections\n",
        "from collections import defaultdict\n",
        "\n",
        "from shutil import copy\n",
        "from shutil import copytree, rmtree\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryNU7UjOZCqr",
        "outputId": "aa310c3b-1f31-4906-f08f-bc5737c70893"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.15.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(tf.__version__)\n",
        "print(tf.test.gpu_device_name())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOq8CACJZHu2"
      },
      "outputs": [],
      "source": [
        "def get_data_extract():\n",
        "  if \"food-101\" in os.listdir():\n",
        "    print(\"Dataset already exists\")\n",
        "  else:\n",
        "    tf.keras.utils.get_file(\n",
        "    'food-101.tar.gz',\n",
        "    'http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz',\n",
        "    cache_subdir='/content',\n",
        "    extract=True,\n",
        "    archive_format='tar',\n",
        "    cache_dir=None\n",
        "    )\n",
        "    print(\"Dataset downloaded and extracted!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAamDyELZMp3",
        "outputId": "e44f756a-93c8-4c7c-893d-fab8639e3648"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
            "4996278331/4996278331 [==============================] - 250s 0us/step\n",
            "Dataset downloaded and extracted!\n"
          ]
        }
      ],
      "source": [
        "get_data_extract()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8mop4Dc9ZctB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JX-gMRkKZaNo"
      },
      "outputs": [],
      "source": [
        "def prepare_data(filepath, src,dest):\n",
        "  classes_images = defaultdict(list)\n",
        "  with open(filepath, 'r') as txt:\n",
        "      paths = [read.strip() for read in txt.readlines()]\n",
        "      for p in paths:\n",
        "        food = p.split('/')\n",
        "        classes_images[food[0]].append(food[1] + '.jpg')\n",
        "\n",
        "  for food in classes_images.keys():\n",
        "    print(\"\\nCopying images into \",food)\n",
        "    if not os.path.exists(os.path.join(dest,food)):\n",
        "      os.makedirs(os.path.join(dest,food))\n",
        "    for i in classes_images[food]:\n",
        "      copy(os.path.join(src,food,i), os.path.join(dest,food,i))\n",
        "  print(\"Copying Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BNArJRbSZfqE",
        "outputId": "bdc9c54e-f330-4cdb-91d1-513b1745ffe8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating train data...\n",
            "\n",
            "Copying images into  apple_pie\n",
            "\n",
            "Copying images into  baby_back_ribs\n",
            "\n",
            "Copying images into  baklava\n",
            "\n",
            "Copying images into  beef_carpaccio\n",
            "\n",
            "Copying images into  beef_tartare\n",
            "\n",
            "Copying images into  beet_salad\n",
            "\n",
            "Copying images into  beignets\n",
            "\n",
            "Copying images into  bibimbap\n",
            "\n",
            "Copying images into  bread_pudding\n",
            "\n",
            "Copying images into  breakfast_burrito\n",
            "\n",
            "Copying images into  bruschetta\n",
            "\n",
            "Copying images into  caesar_salad\n",
            "\n",
            "Copying images into  cannoli\n",
            "\n",
            "Copying images into  caprese_salad\n",
            "\n",
            "Copying images into  carrot_cake\n",
            "\n",
            "Copying images into  ceviche\n",
            "\n",
            "Copying images into  cheesecake\n",
            "\n",
            "Copying images into  cheese_plate\n",
            "\n",
            "Copying images into  chicken_curry\n",
            "\n",
            "Copying images into  chicken_quesadilla\n",
            "\n",
            "Copying images into  chicken_wings\n",
            "\n",
            "Copying images into  chocolate_cake\n",
            "\n",
            "Copying images into  chocolate_mousse\n",
            "\n",
            "Copying images into  churros\n",
            "\n",
            "Copying images into  clam_chowder\n",
            "\n",
            "Copying images into  club_sandwich\n",
            "\n",
            "Copying images into  crab_cakes\n",
            "\n",
            "Copying images into  creme_brulee\n",
            "\n",
            "Copying images into  croque_madame\n",
            "\n",
            "Copying images into  cup_cakes\n",
            "\n",
            "Copying images into  deviled_eggs\n",
            "\n",
            "Copying images into  donuts\n",
            "\n",
            "Copying images into  dumplings\n",
            "\n",
            "Copying images into  edamame\n",
            "\n",
            "Copying images into  eggs_benedict\n",
            "\n",
            "Copying images into  escargots\n",
            "\n",
            "Copying images into  falafel\n",
            "\n",
            "Copying images into  filet_mignon\n",
            "\n",
            "Copying images into  fish_and_chips\n",
            "\n",
            "Copying images into  foie_gras\n",
            "\n",
            "Copying images into  french_fries\n",
            "\n",
            "Copying images into  french_onion_soup\n",
            "\n",
            "Copying images into  french_toast\n",
            "\n",
            "Copying images into  fried_calamari\n",
            "\n",
            "Copying images into  fried_rice\n",
            "\n",
            "Copying images into  frozen_yogurt\n",
            "\n",
            "Copying images into  garlic_bread\n",
            "\n",
            "Copying images into  gnocchi\n",
            "\n",
            "Copying images into  greek_salad\n",
            "\n",
            "Copying images into  grilled_cheese_sandwich\n",
            "\n",
            "Copying images into  grilled_salmon\n",
            "\n",
            "Copying images into  guacamole\n",
            "\n",
            "Copying images into  gyoza\n",
            "\n",
            "Copying images into  hamburger\n",
            "\n",
            "Copying images into  hot_and_sour_soup\n",
            "\n",
            "Copying images into  hot_dog\n",
            "\n",
            "Copying images into  huevos_rancheros\n",
            "\n",
            "Copying images into  hummus\n",
            "\n",
            "Copying images into  ice_cream\n",
            "\n",
            "Copying images into  lasagna\n",
            "\n",
            "Copying images into  lobster_bisque\n",
            "\n",
            "Copying images into  lobster_roll_sandwich\n",
            "\n",
            "Copying images into  macaroni_and_cheese\n",
            "\n",
            "Copying images into  macarons\n",
            "\n",
            "Copying images into  miso_soup\n",
            "\n",
            "Copying images into  mussels\n",
            "\n",
            "Copying images into  nachos\n",
            "\n",
            "Copying images into  omelette\n",
            "\n",
            "Copying images into  onion_rings\n",
            "\n",
            "Copying images into  oysters\n",
            "\n",
            "Copying images into  pad_thai\n",
            "\n",
            "Copying images into  paella\n",
            "\n",
            "Copying images into  pancakes\n",
            "\n",
            "Copying images into  panna_cotta\n",
            "\n",
            "Copying images into  peking_duck\n",
            "\n",
            "Copying images into  pho\n",
            "\n",
            "Copying images into  pizza\n",
            "\n",
            "Copying images into  pork_chop\n",
            "\n",
            "Copying images into  poutine\n",
            "\n",
            "Copying images into  prime_rib\n",
            "\n",
            "Copying images into  pulled_pork_sandwich\n",
            "\n",
            "Copying images into  ramen\n",
            "\n",
            "Copying images into  ravioli\n",
            "\n",
            "Copying images into  red_velvet_cake\n",
            "\n",
            "Copying images into  risotto\n",
            "\n",
            "Copying images into  samosa\n",
            "\n",
            "Copying images into  sashimi\n",
            "\n",
            "Copying images into  scallops\n",
            "\n",
            "Copying images into  seaweed_salad\n",
            "\n",
            "Copying images into  shrimp_and_grits\n",
            "\n",
            "Copying images into  spaghetti_bolognese\n",
            "\n",
            "Copying images into  spaghetti_carbonara\n",
            "\n",
            "Copying images into  spring_rolls\n",
            "\n",
            "Copying images into  steak\n",
            "\n",
            "Copying images into  strawberry_shortcake\n",
            "\n",
            "Copying images into  sushi\n",
            "\n",
            "Copying images into  tacos\n",
            "\n",
            "Copying images into  takoyaki\n",
            "\n",
            "Copying images into  tiramisu\n",
            "\n",
            "Copying images into  tuna_tartare\n",
            "\n",
            "Copying images into  waffles\n",
            "Copying Done!\n"
          ]
        }
      ],
      "source": [
        "print(\"Creating train data...\")\n",
        "prepare_data('food-101/meta/train.txt', 'food-101/images', 'food-101/train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uG4e0R60Zlto",
        "outputId": "5edb0efe-7a0d-4334-9829-47ac99118ff9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating test data...\n",
            "\n",
            "Copying images into  apple_pie\n",
            "\n",
            "Copying images into  baby_back_ribs\n",
            "\n",
            "Copying images into  baklava\n",
            "\n",
            "Copying images into  beef_carpaccio\n",
            "\n",
            "Copying images into  beef_tartare\n",
            "\n",
            "Copying images into  beet_salad\n",
            "\n",
            "Copying images into  beignets\n",
            "\n",
            "Copying images into  bibimbap\n",
            "\n",
            "Copying images into  bread_pudding\n",
            "\n",
            "Copying images into  breakfast_burrito\n",
            "\n",
            "Copying images into  bruschetta\n",
            "\n",
            "Copying images into  caesar_salad\n",
            "\n",
            "Copying images into  cannoli\n",
            "\n",
            "Copying images into  caprese_salad\n",
            "\n",
            "Copying images into  carrot_cake\n",
            "\n",
            "Copying images into  ceviche\n",
            "\n",
            "Copying images into  cheesecake\n",
            "\n",
            "Copying images into  cheese_plate\n",
            "\n",
            "Copying images into  chicken_curry\n",
            "\n",
            "Copying images into  chicken_quesadilla\n",
            "\n",
            "Copying images into  chicken_wings\n",
            "\n",
            "Copying images into  chocolate_cake\n",
            "\n",
            "Copying images into  chocolate_mousse\n",
            "\n",
            "Copying images into  churros\n",
            "\n",
            "Copying images into  clam_chowder\n",
            "\n",
            "Copying images into  club_sandwich\n",
            "\n",
            "Copying images into  crab_cakes\n",
            "\n",
            "Copying images into  creme_brulee\n",
            "\n",
            "Copying images into  croque_madame\n",
            "\n",
            "Copying images into  cup_cakes\n",
            "\n",
            "Copying images into  deviled_eggs\n",
            "\n",
            "Copying images into  donuts\n",
            "\n",
            "Copying images into  dumplings\n",
            "\n",
            "Copying images into  edamame\n",
            "\n",
            "Copying images into  eggs_benedict\n",
            "\n",
            "Copying images into  escargots\n",
            "\n",
            "Copying images into  falafel\n",
            "\n",
            "Copying images into  filet_mignon\n",
            "\n",
            "Copying images into  fish_and_chips\n",
            "\n",
            "Copying images into  foie_gras\n",
            "\n",
            "Copying images into  french_fries\n",
            "\n",
            "Copying images into  french_onion_soup\n",
            "\n",
            "Copying images into  french_toast\n",
            "\n",
            "Copying images into  fried_calamari\n",
            "\n",
            "Copying images into  fried_rice\n",
            "\n",
            "Copying images into  frozen_yogurt\n",
            "\n",
            "Copying images into  garlic_bread\n",
            "\n",
            "Copying images into  gnocchi\n",
            "\n",
            "Copying images into  greek_salad\n",
            "\n",
            "Copying images into  grilled_cheese_sandwich\n",
            "\n",
            "Copying images into  grilled_salmon\n",
            "\n",
            "Copying images into  guacamole\n",
            "\n",
            "Copying images into  gyoza\n",
            "\n",
            "Copying images into  hamburger\n",
            "\n",
            "Copying images into  hot_and_sour_soup\n",
            "\n",
            "Copying images into  hot_dog\n",
            "\n",
            "Copying images into  huevos_rancheros\n",
            "\n",
            "Copying images into  hummus\n",
            "\n",
            "Copying images into  ice_cream\n",
            "\n",
            "Copying images into  lasagna\n",
            "\n",
            "Copying images into  lobster_bisque\n",
            "\n",
            "Copying images into  lobster_roll_sandwich\n",
            "\n",
            "Copying images into  macaroni_and_cheese\n",
            "\n",
            "Copying images into  macarons\n",
            "\n",
            "Copying images into  miso_soup\n",
            "\n",
            "Copying images into  mussels\n",
            "\n",
            "Copying images into  nachos\n",
            "\n",
            "Copying images into  omelette\n",
            "\n",
            "Copying images into  onion_rings\n",
            "\n",
            "Copying images into  oysters\n",
            "\n",
            "Copying images into  pad_thai\n",
            "\n",
            "Copying images into  paella\n",
            "\n",
            "Copying images into  pancakes\n",
            "\n",
            "Copying images into  panna_cotta\n",
            "\n",
            "Copying images into  peking_duck\n",
            "\n",
            "Copying images into  pho\n",
            "\n",
            "Copying images into  pizza\n",
            "\n",
            "Copying images into  pork_chop\n",
            "\n",
            "Copying images into  poutine\n",
            "\n",
            "Copying images into  prime_rib\n",
            "\n",
            "Copying images into  pulled_pork_sandwich\n",
            "\n",
            "Copying images into  ramen\n",
            "\n",
            "Copying images into  ravioli\n",
            "\n",
            "Copying images into  red_velvet_cake\n",
            "\n",
            "Copying images into  risotto\n",
            "\n",
            "Copying images into  samosa\n",
            "\n",
            "Copying images into  sashimi\n",
            "\n",
            "Copying images into  scallops\n",
            "\n",
            "Copying images into  seaweed_salad\n",
            "\n",
            "Copying images into  shrimp_and_grits\n",
            "\n",
            "Copying images into  spaghetti_bolognese\n",
            "\n",
            "Copying images into  spaghetti_carbonara\n",
            "\n",
            "Copying images into  spring_rolls\n",
            "\n",
            "Copying images into  steak\n",
            "\n",
            "Copying images into  strawberry_shortcake\n",
            "\n",
            "Copying images into  sushi\n",
            "\n",
            "Copying images into  tacos\n",
            "\n",
            "Copying images into  takoyaki\n",
            "\n",
            "Copying images into  tiramisu\n",
            "\n",
            "Copying images into  tuna_tartare\n",
            "\n",
            "Copying images into  waffles\n",
            "Copying Done!\n"
          ]
        }
      ],
      "source": [
        "print(\"Creating test data...\")\n",
        "prepare_data('food-101/meta/test.txt', 'food-101/images', 'food-101/test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1x6TMwGtZreh",
        "outputId": "595870e5-29e7-4628-ae68-d3b7874ffd57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of samples in train folder\n",
            "75750\n"
          ]
        }
      ],
      "source": [
        "train_files = sum([len(files) for i, j, files in os.walk(\"food-101/train\")])\n",
        "print(\"Total number of samples in train folder\")\n",
        "print(train_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NXe_6mYWZtV2",
        "outputId": "a20b3a96-27a4-476e-bfdd-ce8cf1f31160"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of samples in test folder\n",
            "25250\n"
          ]
        }
      ],
      "source": [
        "test_files = sum([len(files) for i, j, files in os.walk(\"food-101/test\")])\n",
        "print(\"Total number of samples in test folder\")\n",
        "print(test_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "txiQoLIhZzx9"
      },
      "outputs": [],
      "source": [
        "def dataset_mini(food_list, src, dest):\n",
        "  if os.path.exists(dest):\n",
        "    rmtree(dest) # removing dataset_mini(if it already exists) folders so that we will have only the classes that we want\n",
        "  os.makedirs(dest)\n",
        "  for food_item in food_list :\n",
        "    print(\"Copying images into\",food_item)\n",
        "    copytree(os.path.join(src,food_item), os.path.join(dest,food_item))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xp3Hahr_Z3nS"
      },
      "outputs": [],
      "source": [
        "food_list = ['samosa','pizza','omelette']\n",
        "src_train = 'food-101/train'\n",
        "dest_train = 'food-101/train_mini'\n",
        "src_test = 'food-101/test'\n",
        "dest_test = 'food-101/test_mini'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "JgYeSAxEZ6SX",
        "outputId": "21f612f3-8905-4fb0-a077-be9cca1c5a8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating train data folder with new classes\n",
            "Copying images into samosa\n",
            "Copying images into pizza\n",
            "Copying images into omelette\n"
          ]
        }
      ],
      "source": [
        "print(\"Creating train data folder with new classes\")\n",
        "dataset_mini(food_list, src_train, dest_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OGINkYBHZ9Sw",
        "outputId": "a2687a5e-e347-4f27-debd-6a447e54e254"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of samples in train folder\n",
            "2250\n"
          ]
        }
      ],
      "source": [
        "print(\"Total number of samples in train folder\")\n",
        "train_files = sum([len(files) for i, j, files in os.walk(\"food-101/train_mini\")])\n",
        "print(train_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-VVGkp-HZ9QG",
        "outputId": "120343e6-e912-42d5-c526-0b2e5509e82e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating test data folder with new classes\n",
            "Copying images into samosa\n",
            "Copying images into pizza\n",
            "Copying images into omelette\n"
          ]
        }
      ],
      "source": [
        "print(\"Creating test data folder with new classes\")\n",
        "dataset_mini(food_list, src_test, dest_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_svETTSyZ9NT",
        "outputId": "552c9488-7149-42cf-ae36-2b8fe31ab075"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of samples in test folder\n",
            "750\n"
          ]
        }
      ],
      "source": [
        "print(\"Total number of samples in test folder\")\n",
        "test_files = sum([len(files) for i, j, files in os.walk(\"food-101/test_mini\")])\n",
        "print(test_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "u1-YqZodZ9KX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "c3BO50LbZ9Hm"
      },
      "outputs": [],
      "source": [
        "path_to_train_data = '/content/food-101/train_mini'  # Update this\n",
        "path_to_valid_data = '/content/food-101/test_mini'  # Update this\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCrA_UERZ9D2",
        "outputId": "6582487e-b6c5-4f8a-a8b9-833bedd6b94e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2250 images belonging to 3 classes.\n",
            "Found 750 images belonging to 3 classes.\n",
            "Epoch 1/10\n",
            "141/141 [==============================] - 220s 2s/step - loss: 1.1158 - accuracy: 0.3578 - val_loss: 1.0877 - val_accuracy: 0.3827\n",
            "Epoch 2/10\n",
            "141/141 [==============================] - 222s 2s/step - loss: 0.9857 - accuracy: 0.4818 - val_loss: 0.8748 - val_accuracy: 0.5800\n",
            "Epoch 3/10\n",
            "141/141 [==============================] - 220s 2s/step - loss: 0.9067 - accuracy: 0.5560 - val_loss: 0.7586 - val_accuracy: 0.6920\n",
            "Epoch 4/10\n",
            "141/141 [==============================] - 217s 2s/step - loss: 0.7866 - accuracy: 0.6422 - val_loss: 0.7223 - val_accuracy: 0.6733\n",
            "Epoch 5/10\n",
            "141/141 [==============================] - 228s 2s/step - loss: 0.7252 - accuracy: 0.6756 - val_loss: 0.7714 - val_accuracy: 0.6253\n",
            "Epoch 6/10\n",
            "141/141 [==============================] - 219s 2s/step - loss: 0.7110 - accuracy: 0.6907 - val_loss: 0.5435 - val_accuracy: 0.7907\n",
            "Epoch 7/10\n",
            "141/141 [==============================] - 230s 2s/step - loss: 0.6307 - accuracy: 0.7320 - val_loss: 0.5906 - val_accuracy: 0.7333\n",
            "Epoch 8/10\n",
            "141/141 [==============================] - 220s 2s/step - loss: 0.6250 - accuracy: 0.7307 - val_loss: 0.5541 - val_accuracy: 0.7787\n",
            "Epoch 9/10\n",
            "141/141 [==============================] - 220s 2s/step - loss: 0.5988 - accuracy: 0.7427 - val_loss: 0.5066 - val_accuracy: 0.7840\n",
            "Epoch 10/10\n",
            "141/141 [==============================] - 226s 2s/step - loss: 0.5697 - accuracy: 0.7644 - val_loss: 0.6264 - val_accuracy: 0.7267\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\", input_shape=(224, 224, 3)))\n",
        "model.add(MaxPool2D())\n",
        "\n",
        "model.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D())\n",
        "\n",
        "model.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation=\"relu\"))\n",
        "model.add(Dense(3, activation=\"softmax\"))  # Assuming 3 classes in your dataset\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Data Augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255.0,\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.2,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    path_to_train_data,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=16,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "valid_generator = test_datagen.flow_from_directory(\n",
        "    path_to_valid_data,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=16,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Train the custom model on your dataset\n",
        "history=model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    epochs=10,\n",
        "    validation_data=valid_generator,\n",
        "    validation_steps=len(valid_generator)\n",
        ")\n",
        "\n",
        "# Save the trained model\n",
        "model.save('bestmodel.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlbtxbyPFoIO",
        "outputId": "ab8b5f31-91c2-4f76-a1d2-091dcd08f8c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.35.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n",
            "Requirement already satisfied: packaging<25,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.0)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.11.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.0.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ly1HidxPyQ-O",
        "outputId": "bf33cbb9-0032-4976-bf93-5a5eaee90222"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gTTS in /usr/local/lib/python3.10/dist-packages (2.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gTTS) (2.31.0)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gTTS) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gTTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKkoAoa5Z8_D",
        "outputId": "ccfa6676-4071-454c-b09a-eca290a2d388"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting aapp.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile aapp.py\n",
        "import numpy as np\n",
        "import streamlit as st\n",
        "import tensorflow as tf\n",
        "from PIL import Image, ImageOps\n",
        "from gtts import gTTS\n",
        "\n",
        "def import_and_predict(image_data, model):\n",
        "    size = (299, 299)\n",
        "    image = ImageOps.fit(image_data, size, method=Image.LANCZOS)\n",
        "    image = image.convert('RGB')\n",
        "    image = np.asarray(image)\n",
        "    image = (image.astype(np.float32) / 255.0)\n",
        "    img_reshape = image[np.newaxis, ...]\n",
        "    prediction = model.predict(img_reshape)\n",
        "    return prediction\n",
        "\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/bestmodel_6class.hdf5')\n",
        "\n",
        "\n",
        "st.write(\"\"\"\n",
        "         # Food Prediction by Nikhil M\n",
        "          Guide- Mr. Prasad K\n",
        "         \"\"\"\n",
        "         )\n",
        "\n",
        "st.write(\"This is a simple image classification web app to predict food item names\")\n",
        "\n",
        "file = st.file_uploader(\"Please upload an image file\", type=[\"jpg\", \"png\"])\n",
        "\n",
        "food_classes = ['frenchfries', 'icecream', 'omelette', 'pizza', 'samosa', 'springrolls']\n",
        "\n",
        "if file is None:\n",
        "    st.text(\"You haven't uploaded an image file\")\n",
        "else:\n",
        "    image = Image.open(file)\n",
        "    st.image(image, use_column_width=True)\n",
        "    prediction = import_and_predict(image, model)\n",
        "\n",
        "    st.write(\"Prediction:\")\n",
        "    if np.argmax(prediction) == 0:\n",
        "        st.write(\"It is french fries!\")\n",
        "    elif np.argmax(prediction) == 1:\n",
        "        st.write(\"It is an ice cream!\")\n",
        "    elif np.argmax(prediction) == 2:\n",
        "        st.write(\"It is an omelette!\")\n",
        "    elif np.argmax(prediction) == 3:\n",
        "        st.write(\"It is a pizza!\")\n",
        "    elif np.argmax(prediction) == 4:\n",
        "        st.write(\"It is a samosa!\")\n",
        "    elif np.argmax(prediction) == 5:\n",
        "        st.write(\"It is spring rolls!\")\n",
        "\n",
        "    # Text-to-speech\n",
        "    text_to_speech = f\"It is a {food_classes[np.argmax(prediction)]}!\"\n",
        "    tts = gTTS(text=text_to_speech, lang='en')\n",
        "    tts.save(\"output.mp3\")\n",
        "\n",
        "    # Play audio\n",
        "    st.audio(\"output.mp3\", format=\"audio/mp3\", start_time=0)\n",
        "\n",
        "    #st.write(\"Probability:\")\n",
        "    probabilities = {food_classes[i]: prediction[0][i] for i in range(len(food_classes))}\n",
        "    #st.write(probabilities)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wh_0Tx3iYiLW",
        "outputId": "b0aa15d4-ce1e-4dd9-a8d1-796bf8b40967"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.35.0)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n",
            "Requirement already satisfied: packaging<25,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.0)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.11.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: watchdog>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.0.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6o6cJ-kMbTiq",
        "outputId": "909c51bd-5e9e-49ec-a942-cdd4b5deb9ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.90.144.16\n"
          ]
        }
      ],
      "source": [
        "!curl -s ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1xOMt7WbTf2",
        "outputId": "c94d4c7d-cbd6-4d15-a637-d0a4b396f625"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.90.144.16:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 4.991s\n",
            "your url is: https://mean-sloths-lead.loca.lt\n",
            "2024-05-29 17:25:56.583818: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-05-29 17:25:56.583882: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-05-29 17:25:56.585987: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-05-29 17:25:56.599429: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-05-29 17:25:58.750627: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run aapp.py & npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kb0AzfPU1Y0Y"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get the training history\n",
        "training_loss = model.history.history['loss']\n",
        "validation_loss = model.history.history['val_loss']\n",
        "training_accuracy = model.history.history['accuracy']\n",
        "validation_accuracy = model.history.history['val_accuracy']\n",
        "\n",
        "# Number of epochs\n",
        "epochs = range(1, len(training_loss) + 1)\n",
        "\n",
        "# Plot training and validation loss\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, training_loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, validation_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs, training_accuracy, 'r', label='Training Accuracy')\n",
        "plt.plot(epochs, validation_accuracy, 'b', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKyBOO5_8xlo"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/drive/MyDrive/bestmodel_6class.hdf5\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}